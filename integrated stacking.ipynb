{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we shall be using neural networks as meta-learner for three sub-models. Integrated Stacking is basically a way of aggregating all the prdictions of the preditors in an ensemble using deep neural nets. The output predictions of all the submodels are used as input for the meta-learner. By doing this the accuracy of the final models increase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('dataset/X_test.csv')\n",
    "y_test = pd.read_csv('dataset/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>release_date</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>credits</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barbara Hammer Lends a Hand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28-03-2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Barbara Hammer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuck Private Property!</td>\n",
       "      <td>Drama</td>\n",
       "      <td>en</td>\n",
       "      <td>France 2045. In the midst of a food crisis Ale...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-02-2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FEMMEfille</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>fr</td>\n",
       "      <td>The story of Isabelle Caro Oliviero Toscani's ...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>Tag/Traum Filmproduktion</td>\n",
       "      <td>29-10-2014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Kiki Allgeier-Oliviero Toscani-Isabelle Caro</td>\n",
       "      <td>anorexia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My Mother Is a Parrot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>Juana an eleven-year-old girl comes from a ver...</td>\n",
       "      <td>1.400</td>\n",
       "      <td>Masa Latina</td>\n",
       "      <td>12-10-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Valentina Marcone-Gabriel P치ez-Natalia Se침oral...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Prairie Home Companion</td>\n",
       "      <td>Drama-Comedy-Music</td>\n",
       "      <td>en</td>\n",
       "      <td>A look at what goes on backstage during the la...</td>\n",
       "      <td>7.849</td>\n",
       "      <td>Sandcastle 5-Prairie Home Productions-Ivanhoe ...</td>\n",
       "      <td>09-06-2006</td>\n",
       "      <td>10000000</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Released</td>\n",
       "      <td>Radio like you've never seen it before.</td>\n",
       "      <td>241</td>\n",
       "      <td>Meryl Streep-Lily Tomlin-Lindsay Lohan-Garriso...</td>\n",
       "      <td>country music-commercial-minnesota-radio prese...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title              genres original_language  \\\n",
       "0  Barbara Hammer Lends a Hand                 NaN                en   \n",
       "1       Fuck Private Property!               Drama                en   \n",
       "2                   FEMMEfille         Documentary                fr   \n",
       "3        My Mother Is a Parrot                 NaN                es   \n",
       "4     A Prairie Home Companion  Drama-Comedy-Music                en   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0                                                NaN       0.600   \n",
       "1  France 2045. In the midst of a food crisis Ale...       0.600   \n",
       "2  The story of Isabelle Caro Oliviero Toscani's ...       0.600   \n",
       "3  Juana an eleven-year-old girl comes from a ver...       1.400   \n",
       "4  A look at what goes on backstage during the la...       7.849   \n",
       "\n",
       "                                production_companies release_date    budget  \\\n",
       "0                                                NaN   28-03-2012         0   \n",
       "1                                                NaN   01-02-2022         0   \n",
       "2                           Tag/Traum Filmproduktion   29-10-2014         0   \n",
       "3                                        Masa Latina   12-10-2017         0   \n",
       "4  Sandcastle 5-Prairie Home Productions-Ivanhoe ...   09-06-2006  10000000   \n",
       "\n",
       "   revenue  runtime    status                                  tagline  \\\n",
       "0        0      1.0  Released                                      NaN   \n",
       "1        0     15.0  Released                                      NaN   \n",
       "2        0      0.0  Released                                      NaN   \n",
       "3        0     81.0  Released                                      NaN   \n",
       "4        0    105.0  Released  Radio like you've never seen it before.   \n",
       "\n",
       "   vote_count                                            credits  \\\n",
       "0           0                                     Barbara Hammer   \n",
       "1           0                                                NaN   \n",
       "2           1       Kiki Allgeier-Oliviero Toscani-Isabelle Caro   \n",
       "3           2  Valentina Marcone-Gabriel P치ez-Natalia Se침oral...   \n",
       "4         241  Meryl Streep-Lily Tomlin-Lindsay Lohan-Garriso...   \n",
       "\n",
       "                                            keywords  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                           anorexia  \n",
       "3                                                NaN  \n",
       "4  country music-commercial-minnesota-radio prese...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_Converter(data):\n",
    "    X1 = data[['vote_count', 'runtime', 'revenue', 'budget', 'popularity', 'original_language', 'status']]\n",
    "    X2 = data[['genres','credits']]\n",
    "    X3 = data[['overview']]\n",
    "    X4 = data[['keywords']]\n",
    "    return X1, X2, X3, X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_model = X_test.iloc[:-1]\n",
    "X_predict = X_test.iloc[X_test.shape[0]-1]\n",
    "y_model = y_test.iloc[:-1]\n",
    "y_predict = y_test.iloc[y_test.shape[0]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_model.shape\n",
    "y_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tranformer = pickle.load(open('dataset/category_tranformer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tranformer_2 = pickle.load(open('dataset/category_tranformer_2.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pickle.load(open('/home/dwip.dalal/movies_rating_prediction/tokenizer.pickle', 'rb'))\n",
    "tokenizer_2 = pickle.load(open('/home/dwip.dalal/movies_rating_prediction/tokenizer_2.pickle', 'rb'))\n",
    "tokenizer_3 = pickle.load(open('/home/dwip.dalal/movies_rating_prediction/tokenizer_3.pickle', 'rb'))\n",
    "tokenizer_4 = pickle.load(open('/home/dwip.dalal/movies_rating_prediction/tokenizer_4.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2, X3, X4 = data_Converter(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = 0\n",
    "def find_len(sequence_train):\n",
    "    for i in sequence_train:\n",
    "        maxi = max(len(i), maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1['original_language'] = category_tranformer.transform(X1['original_language'])\n",
    "X1['status'] = category_tranformer_2.transform(X1['status'])\n",
    "sequence_train = tokenizer.texts_to_sequences(X2['genres'])\n",
    "sequence_train_2 = tokenizer_2.texts_to_sequences(X2['credits'])\n",
    "sequence_train_3 = tokenizer_3.texts_to_sequences(X3['overview'])\n",
    "sequence_train_4 = tokenizer_4.texts_to_sequences(X4['keywords'])\n",
    "\n",
    "X2['genres'] = pad_sequences(sequence_train, maxlen= find_len(sequence_train))\n",
    "X2['credits'] = pad_sequences(sequence_train_2, maxlen= find_len(sequence_train_2))\n",
    "X3['overview'] = pad_sequences(sequence_train_3, maxlen= find_len(sequence_train_3))\n",
    "X4['keywords'] = pad_sequences(sequence_train_4, maxlen= find_len(sequence_train_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "model1 = tf.keras.models.load_model('/home/dwip.dalal/movies_rating_prediction/Weights-048--0.61986.hX_train5')\n",
    "model2 = tf.keras.models.load_model('/home/dwip.dalal/movies_rating_prediction/Weights_2_-071--0.71807.hX_train5')\n",
    "model3 = tf.keras.models.load_model('/home/dwip.dalal/movies_rating_prediction/Weights_3_-062--0.65039.hX_train5')\n",
    "model4 = tf.keras.models.load_model('/home/dwip.dalal/movies_rating_prediction/Weights_4_-112--0.55039.hX_train5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_layer_names = ['dense_2', 'dense_3', 'dense_4', 'dense_5']\n",
    "model2_layer_names = ['embedding', 'lstm', 'lstm_1', 'dense_6', 'dense_7', 'dense_8']\n",
    "model3_layer_names = ['dense_9', 'dense_10', 'dense_11']\n",
    "model4_layer_names = ['embedding_2', 'lstm_2', 'lstm_1_2', 'dense_12', 'dense_13', 'dense_14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0\n",
    "for layer in model1.layers:\n",
    "  layer._name = model1_layer_names[p]\n",
    "  p += 1\n",
    "p = 0\n",
    "for layer in model2.layers:\n",
    "  layer._name = model2_layer_names[p]\n",
    "  p += 1\n",
    "p = 0\n",
    "for layer in model3.layers:\n",
    "  layer._name = model3_layer_names[p]\n",
    "  p += 1\n",
    "p = 0\n",
    "for layer in model4.layers:\n",
    "  layer._name = model4_layer_names[p]\n",
    "  p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.layers[0].input._name = 'dense_input_1'\n",
    "model4.layers[0].input._name = 'embedding_input_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_input_1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.layers[0].input._name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1._input_layers[0]._name = \"dense_input_1\"\n",
    "model4._input_layers[0]._name = 'embedding_input_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(model1)\n",
    "a.append(model2)\n",
    "a.append(model3)\n",
    "a.append(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_model(members):\n",
    "\t# here we don't want to upload the weights of our already pretrained model so we have to upadte all layers in all models to not be trainable.\n",
    "  # print(members)\n",
    "  for i in range(len(members)):\n",
    "    model = members[i]\n",
    "    for layer in model.layers:\n",
    "      layer.trainable = False\n",
    "\t\t\t\n",
    "\t# define multi-headed input\n",
    "  ensemble_visible = [model.input for model in members]\n",
    "  print(ensemble_visible)\n",
    "  # concatenate merge output from each model\n",
    "  ensemble_outputs = [model.output for model in members]\n",
    "  print(ensemble_outputs)\n",
    "  merge = Concatenate()(ensemble_outputs)\n",
    "\n",
    "  hidden = keras.layers.Dense(7, activation='relu')(merge)\n",
    "  output = keras.layers.Dense(1, activation='linear')(hidden)\n",
    "  model = tf.keras.Model(inputs=ensemble_visible, outputs=output)\n",
    "  plot_model(model, show_shapes=True, to_file='model.png')\n",
    "  \n",
    "  model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'dense_input_1')>, <KerasTensor: shape=(None, 52) dtype=float32 (created by layer 'embedding_input')>, <KerasTensor: shape=(None, 653) dtype=float32 (created by layer 'dense_input')>, <KerasTensor: shape=(None, 52) dtype=float32 (created by layer 'embedding_input_1')>]\n",
      "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_5')>, <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_8')>, <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_11')>, <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense_14')>]\n"
     ]
    }
   ],
   "source": [
    "final_model = stacked_model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'dense_input_1')>,\n",
       " <KerasTensor: shape=(None, 52) dtype=float32 (created by layer 'embedding_input')>,\n",
       " <KerasTensor: shape=(None, 653) dtype=float32 (created by layer 'dense_input')>,\n",
       " <KerasTensor: shape=(None, 52) dtype=float32 (created by layer 'embedding_input_1')>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = final_model.fit([X1, X2, X3, X4], y_predict,epochs = 14, verbose = 2,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a class for making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vote_average    4.8\n",
       "Name: 15360, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data input would be:\n",
    "X_predict\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prediction():\n",
    "    def __init__(self, X_predict):\n",
    "        self.X_predict = X_predict\n",
    "\n",
    "    def split_data(self):\n",
    "        self.X1, self.X2, self.X3, self.X4 = data_Converter(self.X_predict)\n",
    "\n",
    "    def preprocess(self):\n",
    "        self.X1['original_language'] = category_tranformer.transform(self.X1['original_language'])\n",
    "        self.X1['status'] = category_tranformer_2.transform(self.X1['status'])\n",
    "        sequence_train = tokenizer.texts_to_sequences(self.X2['genres'])\n",
    "        sequence_train_2 = tokenizer_2.texts_to_sequences(self.X2['credits'])\n",
    "        sequence_train_3 = tokenizer_3.texts_to_sequences(self.X3['overview'])\n",
    "        sequence_train_4 = tokenizer_4.texts_to_sequences(self.X4['keywords'])\n",
    "\n",
    "        self.X2['genres'] = pad_sequences(sequence_train, maxlen= find_len(sequence_train))\n",
    "        self.X2['credits'] = pad_sequences(sequence_train_2, maxlen= find_len(sequence_train_2))\n",
    "        self.X3['overview'] = pad_sequences(sequence_train_3, maxlen= find_len(sequence_train_3))\n",
    "        self.X4['keywords'] = pad_sequences(sequence_train_4, maxlen= find_len(sequence_train_4))\n",
    "        \n",
    "    def predict(self):\n",
    "        return final_model.predict([self.X1, self.X2, self.X3, self.X4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.predict(X_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pal': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99bd79105e31133f60409838afb54ed31553801c2675cfb9257695e9fe28666d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
